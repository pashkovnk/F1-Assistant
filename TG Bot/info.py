import os
import time

import requests
from bs4 import BeautifulSoup
from googletrans import Translator

from config import flagsEmoji, ticketsToBahrain, current_year, teamURLs, teamPhotoURLs, driverURLs, driverPhotoURLs
import random

def openDB():
    from database import BotDB
    BotDB = BotDB('F1Assistant.db')
    return BotDB


translator = Translator()


def getCalendar(year, *toUpdate):
    database = openDB()
    if ((not database.year_exists(year)) or (toUpdate == True)) and (year <= current_year):
        responce = requests.get(f'https://ru.motorsport.com/f1/schedule/{year}')
        bs = BeautifulSoup(responce.text, 'lxml')
        try:
            GP_Links = bs.find_all('tr', class_='ms-schedule-table__item-main')
            for i in GP_Links:
                if i.find_next('div', class_='ms-schedule-table-item-main__info').find_next('a', class_='ms-link').get(
                        'href')[:4] == "/f1/":
                    GP_Link = "https://ru.motorsport.com" + i.find_next('div',
                                                                        class_='ms-schedule-table-item-main__info').find_next(
                        'a', class_='ms-link').get('href')
                    GP_Links[GP_Links.index(i)] = GP_Link
                else:
                    GP_Data = i.find_next('div', class_='ms-schedule-table-date ms-schedule-table-date--your').find_all(
                        'span')
                    GP_Data = [data.text for data in GP_Data]
                    GP_Data[0] = f"{''.join(list(GP_Data[0])[:-2])} {GP_Data[1]}"
                    GP_Data.remove(GP_Data[1])
                    GP_Data.append(i.find_next('h2').text)
                    GP_Data.append(
                        f"{translator.translate(translator.translate(i.find_next('h2').text.split()[-1], dest='en').text, dest='ru').text} {flagsEmoji.get(translator.translate((i.find_next('h2').text.split())[-1], dest='en').text.lower())}")
                    GP_Data.append(i.find_next('td',
                                               class_='ms-schedule-table__cell ms-schedule-table__cell--status ms-schedule-table__cell--status-finished').text)
                    GP_Links[GP_Links.index(i)] = GP_Data
        except AttributeError:
            calendar = f"<b>–Ø –Ω–µ –Ω–∞—à–µ–ª –∫–∞–ª–µ–Ω–¥–∞—Ä—å –§–æ—Ä–º—É–ª—ã-1 —Å–µ–∑–æ–Ω–∞ {year} üòû</b>\n–ü–æ–ø—Ä–æ—Å–∏—Ç–µ –µ–≥–æ —É –º–µ–Ω—è –ø–æ–∑–∂–µ, –≤–æ–∑–º–æ–∂–Ω–æ —è —Å–º–æ–≥—É –µ–≥–æ –≤–∞–º –ø–æ–∫–∞–∑–∞—Ç—å"
            return calendar
        GPs = []
        calendar = f"<b>–ö–∞–ª–µ–Ω–¥–∞—Ä—å —Å–µ–∑–æ–Ω–∞ –§–æ—Ä–º—É–ª—ã-1 {year}:</b>\n"
        for link in GP_Links:
            if link[:5] == "https":
                responce = requests.get(link)
                bs = BeautifulSoup(responce.text, 'lxml')
                try:
                    GP_Info = [
                        " ".join(bs.find('div', class_='ms-entity-header_wrapper ms-ml').find('h1').text.split()[:-1]),
                        [i.text for i in bs.find_all('span', class_='ms-event-header-period_day')],
                        [i.text for i in bs.find_all('span', class_='ms-event-header-period_month')],
                        [bs.find('div', class_='ms-event-header_location').find('span').text,
                         bs.find('div', class_='ms-event-header_location').find('a').text],
                        bs.find('span', class_='ms-schedule-item_results-title').text,
                    ]
                    GP_Info = [GP_Info[0], GP_Info[1][0] + " " + GP_Info[2][0], GP_Info[1][1] + " " + GP_Info[2][1],
                               GP_Info[3][0],
                               translator.translate(str(GP_Info[3][0]), dest='en').text.lower(), GP_Info[3][1],
                               GP_Info[
                                   4]]  # –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é, —á—Ç–æ–±—ã –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –≤ —É–¥–æ–±–Ω–æ–º –æ–¥–Ω–æ–º–µ—Ä–Ω–æ–º —Å–ø–∏—Å–∫–µ [–ò–º—è –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è, –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞, –¥–∞—Ç–∞ –∫–æ–Ω—Ü–∞, —Å—Ç—Ä–∞–Ω–∞, –∫–æ–¥ –¥–ª—è —Ñ–ª–∞–≥–∞ —Å—Ç—Ä–∞–Ω—ã, –¢—Ä–∞—Å—Å–∞, –°—Ç–∞—Ç—É—Å –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è]
                    GPs.append(GP_Info)
                except AttributeError:
                    if (GP_Links.index(link) + 1) != len(GP_Links):
                        continue
                    else:
                        if len(GPs) != 0:
                            for GP in GPs:
                                calendar += f"\n{GPs.index(GP) + 1}.  <b>{GP[0]}</b>    {GP[1]} ‚Äî {GP[2]}" \
                                            f"\n    {len(str(GPs.index(GP) + 1)) ** 2 * ' '}<b>–°—Ç—Ä–∞–Ω–∞:</b> {GP[3]} {flagsEmoji.get(GP[4])}" \
                                            f"\n    {len(str(GPs.index(GP) + 1)) ** 2 * ' '}<b>–¢—Ä–∞—Å—Å–∞:</b> {GP[5]}" \
                                            f"\n    {len(str(GPs.index(GP) + 1)) ** 2 * ' '}<b>–°—Ç–∞—Ç—É—Å:</b> {GP[6]}\n"
                            return calendar
                        else:
                            calendar = f"<b>–Ø –Ω–µ –Ω–∞—à–µ–ª –∫–∞–ª–µ–Ω–¥–∞—Ä—å –§–æ—Ä–º—É–ª—ã-1 —Å–µ–∑–æ–Ω–∞ {year} üòû</b>\n–ü–æ–ø—Ä–æ—Å–∏—Ç–µ –µ–≥–æ —É –º–µ–Ω—è –ø–æ–∑–∂–µ, –≤–æ–∑–º–æ–∂–Ω–æ —è —Å–º–æ–≥—É –µ–≥–æ –≤–∞–º –ø–æ–∫–∞–∑–∞—Ç—å"
                            return calendar
            else:
                GPs.append(link)
        for GP in GPs:
            if len(GP) != 4:
                calendar += f"\n{GPs.index(GP) + 1}.  <b>{GP[0]}</b>    {GP[1]} ‚Äî {GP[2]}" \
                            f"\n    {len(str(GPs.index(GP) + 1)) ** 2 * ' '}<b>–°—Ç—Ä–∞–Ω–∞:</b> {GP[3]} {flagsEmoji.get(GP[4])}" \
                            f"\n    {len(str(GPs.index(GP) + 1)) ** 2 * ' '}<b>–¢—Ä–∞—Å—Å–∞:</b> {GP[5]}" \
                            f"\n    {len(str(GPs.index(GP) + 1)) ** 2 * ' '}<b>–°—Ç–∞—Ç—É—Å:</b> {GP[6]}\n"
            else:
                calendar += f"\n{GPs.index(GP) + 1}.  <b>{GP[1]}</b>    {GP[0]}" \
                            f"\n    {len(str(GPs.index(GP) + 1)) ** 2 * ' '}<b>–°—Ç—Ä–∞–Ω–∞:</b> {GP[2]}" \
                            f"\n    {len(str(GPs.index(GP) + 1)) ** 2 * ' '}<b>–°—Ç–∞—Ç—É—Å:</b> {GP[3]}\n"
        database.add_info_calendar(year, calendar)
    else:
        if year > current_year:
            calendar = f"<b>–Ø –Ω–µ –Ω–∞—à–µ–ª –∫–∞–ª–µ–Ω–¥–∞—Ä—å –§–æ—Ä–º—É–ª—ã-1 —Å–µ–∑–æ–Ω–∞ {year} üòû</b>\n–ü–æ–ø—Ä–æ—Å–∏—Ç–µ –µ–≥–æ —É –º–µ–Ω—è –ø–æ–∑–∂–µ, –≤–æ–∑–º–æ–∂–Ω–æ —è —Å–º–æ–≥—É –µ–≥–æ –≤–∞–º –ø–æ–∫–∞–∑–∞—Ç—å"
            return calendar
        calendar = database.get_calendar(str(year))[0][0]
    database.close()
    return calendar


def getTeamInfo(url, urlPhoto, *toUpdate):
    database = openDB()
    countOfExtraMessages = 1
    response = requests.get(url)
    bs = BeautifulSoup(response.text, "lxml")
    teamName = " ".join(bs.find('h1').text.split())
    if (not database.team_exists(teamName)) or (toUpdate == True):
        teamData = bs.find('table').find('div', class_='midpart').find_all('tr')[3]
        # –ù–∏–∂–µ teamShortedData —Ö—Ä–∞–Ω–∏—Ç –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –∫–æ–º–∞–Ω–¥—ã –í–∏–ª—å—è–º—Å) (–í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏—è, –ê—Ä–≥–µ–Ω—Ç–∏–Ω–∞'1975...)
        teamData = teamData.find_all_next('tr')[0].find_all_next('div', class_='news8')
        teamData = [data.text.split() for data in teamData][:-3]
        debut = ", ".join(teamData[1][0].split("\'"))
        teamShortedInfo = f"<b>{teamName}</b>" \
                          f"\n\n<b>C—Ç—Ä–∞–Ω–∞:</b> {teamData[0][0]} {flagsEmoji.get(translator.translate(teamData[0][0], dest='en').text.lower())}" \
                          f"\n<b>–î–µ–±—é—Ç:</b> {debut}"
        teamDetailedInfo_1 = f"<b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–º–∞–Ω–¥—ã:</b>\n\n"
        if " ".join(bs.find('table', class_='f1menu').find_all('div', class_='news8b')[
                        9].text.split()) != '–ö—É–±–∫–∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–æ–≤':
            teamDetailedInfo_1 += f"<b>–õ—É—á—à–µ–µ –º–µ—Å—Ç–æ –≤ –ö—É–±–∫–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–æ–≤:</b> {teamData[12][0]}"
        else:
            teamDetailedInfo_1 += f"<b>–ö—É–±–∫–∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–æ–≤:</b> {teamData[12][0]} üèÜ"
        if " ".join(
                bs.find('table', class_='f1menu').find_all('div', class_='news8b')[
                    8].text.split()) != '–ß–µ–º–ø–∏–æ–Ω—Å–∫–∏–µ —Ç–∏—Ç—É–ª—ã':
            teamDetailedInfo_1 += f"\n<b>–õ—É—á—à–µ–µ –º–µ—Å—Ç–æ –≤ —á–µ–º–ø–∏–æ–Ω–∞—Ç–µ –ø–∏–ª–æ—Ç–æ–≤:</b> {teamData[11][0]}"
        else:
            teamDetailedInfo_1 += f"\n<b>–ß–µ–º–ø–∏–æ–Ω—Å–∫–∏–µ —Ç–∏—Ç—É–ª—ã –ø–∏–ª–æ—Ç–æ–≤:</b> {teamData[11][0]} üèÜ"
        teamDetailedInfo_1 += f"\n<b>–£—á–∞—Å—Ç–∏–π –≤ –ì—Ä–∞–Ω-–ø—Ä–∏:</b> {teamData[3][0]}" \
                              f"\n<b>C—Ç–∞—Ä—Ç—ã –≤ –ì—Ä–∞–Ω-–ø—Ä–∏:</b> {teamData[5][0]}"
        if "".join(bs.find('table', class_='f1menu').find_all('div', class_='news8b')[4].text.split()) != '–ü–æ–±–µ–¥—ã':
            teamDetailedInfo_1 += f"\n<b>–õ—É—á—à–µ–µ –º–µ—Å—Ç–æ –≤ –≥–æ–Ω–∫–µ:</b> {teamData[7][0]}"
        else:
            teamDetailedInfo_1 += f"\n<b>–ü–æ–¥–∏—É–º—ã:</b> {teamData[6][0]}" \
                                  f"\n‚Äî –ü–æ–±–µ–¥—ã: {teamData[7][0]} ü•á"
        teamDetailedInfo_1 += f"\n<b>–ü–æ—É–ª-–ø–æ–∑–∏—Ü–∏–∏:</b> {teamData[4][0]}" \
                              f"\n<b>–ü–µ—Ä–≤—ã–µ –ª–∏–Ω–∏–∏:</b> {teamData[6][0]}" \
                              f"\n<b>–õ—É—á—à–∏–µ –∫—Ä—É–≥–∏:</b> {teamData[8][0]}" \
                              f"\n<b>–ó–∞—á–µ—Ç–Ω—ã–µ –æ—á–∫–∏:</b> {teamData[10][0]}\n\n"
        yearStatistics = []
        teamDetailedInfo_2 = f"<b>–ì–æ–¥ –ö–æ–º–∞–Ω–¥–∞ ‚Äî –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å –¥–≤–∏–≥–∞—Ç–µ–ª–µ–π</b> ‚Äî –°—Ç–∞—Ä—Ç—ã ‚Äî –û—á–∫–∏ ‚Äî –ü–æ–¥–∏—É–º—ã ‚Äî –ü–æ–±–µ–¥—ã ‚Äî –ü–æ—É–ª-–ø–æ–∑–∏—Ü–∏–∏ ‚Äî –õ—É—á—à–∏–µ –∫—Ä—É–≥–∏ ‚Äî –ú–µ—Å—Ç–æ –≤ –∫—É–±–∫–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–æ–≤\n\n"
        teamDetailedInfo_3 = ""
        for dataUnit in teamData[13:]:
            if len(yearStatistics) < 3:
                if len(dataUnit) == 1 and dataUnit != [] and len(dataUnit[0]) == 4:
                    yearStatistics.append(dataUnit[0])
                    continue
                if len(dataUnit) not in [1, 2] and len(yearStatistics) != 2:
                    motorCompanyName = ""
                    for data in dataUnit:
                        if data not in teamName.split() and list(data)[0] != '(':
                            motorCompanyName += f"{data} "
                        elif list(data)[0] == '(' and len(yearStatistics) == 1:
                            if motorCompanyName == "":
                                yearStatistics.append(teamName)
                            else:
                                yearStatistics.append(motorCompanyName)
                            break
                if len(yearStatistics) == 2:
                    fullTeamName = dataUnit[dataUnit.index(yearStatistics[-1].split()[-1]) + 1: dataUnit.index('-')]
                    if len(fullTeamName) == 1:
                        fullTeamName = "".join(list(fullTeamName[0])[1:-1])
                    else:
                        fullTeamName = f"{''.join(list(fullTeamName[0])[1:])} {' '.join(fullTeamName[1:-1])} {''.join(list(fullTeamName[-1][:-1]))}"
                    yearStatistics.append(fullTeamName)
                continue
            else:
                if dataUnit == []:
                    dataUnit = '0'
                    yearStatistics.append(dataUnit)
                    continue
                elif (len(dataUnit) == 2 and dataUnit[1] == '–º–µ—Å—Ç–æ') or (dataUnit == ['=']):
                    if dataUnit == ['=']:
                        dataUnit = ["–Ω/–º"]
                    yearStatistics.append(" ".join(dataUnit))
                    if len(teamDetailedInfo_2) + len(
                            f"<b>{yearStatistics[0]} {yearStatistics[2]} ‚Äî {yearStatistics[1]}</b>" \
                            f" ‚Äî {' ‚Äî '.join(yearStatistics[3:])}\n") <= 4096:
                        teamDetailedInfo_2 += f"<b>{yearStatistics[0]} {yearStatistics[2]} ‚Äî {yearStatistics[1]}</b>" \
                                              f" ‚Äî {' ‚Äî '.join(yearStatistics[3:])}\n"
                    else:
                        teamDetailedInfo_3 += f"<b>{yearStatistics[0]} {yearStatistics[2]} ‚Äî {yearStatistics[1]}</b>" \
                                              f" ‚Äî {' ‚Äî '.join(yearStatistics[3:])}\n"
                    yearStatistics = []
                    continue
                else:
                    yearStatistics.append(dataUnit[0])
        if teamDetailedInfo_3 != "":
            countOfExtraMessages += 1
            teamDetailedInfo_3 += f"\n<b>–Ω/–º</b> ‚Äî –ù–µ—Ç –º–µ—Å—Ç–∞"
        response = requests.get(urlPhoto)
        bs = BeautifulSoup(response.text, "lxml")
        teamDrivers = [driver.get('alt') for driver in bs.find('div', class_='ms-grid ms-grid-vert').find_all('img')]
        teamShortedInfo += f"\n<b>–¢–µ–∫—É—â–∏–π —Å–æ—Å—Ç–∞–≤ –ø–∏–ª–æ—Ç–æ–≤:</b> {teamDrivers[0]}, {teamDrivers[1]}"
        teamLogo = bs.find('div', class_='ms-entity-header_img-wrapper').find('img',
                                                                              class_='ms-item_img ms-item_img--3_2').get(

            'src')
        if not os.path.exists('teamPics/'):
            os.mkdir('teamPics/')
        imageData = requests.get(teamLogo, verify=False).content
        with open('teamPics/' + teamName + '.jpg', 'wb') as handler:
            handler.write(imageData)
        teamDetailedInfo = [teamDetailedInfo_1, teamDetailedInfo_2, teamDetailedInfo_3]
        database.add_info_team(teamName, teamDetailedInfo_1, teamDetailedInfo_2, teamDetailedInfo_3, teamShortedInfo,
                               teamDrivers[0], teamDrivers[1], countOfExtraMessages)
        return teamDetailedInfo, teamName, teamShortedInfo, teamDrivers, countOfExtraMessages
    else:
        if not os.path.exists('teamPics/'):
            os.mkdir('teamPics/')
            response = requests.get(urlPhoto)
            bs = BeautifulSoup(response.text, "lxml")
            teamLogo = bs.find('div', class_='ms-entity-header_img-wrapper').find('img',
                                                                                  class_='ms-item_img ms-item_img--3_2').get(

                'src')
            imageData = requests.get(teamLogo, verify=False).content
            with open('teamPics/' + teamName + '.jpg', 'wb') as handler:
                handler.write(imageData)
        elif not os.path.exists('teamPics/' + teamName + '.jpg'):
            response = requests.get(urlPhoto)
            bs = BeautifulSoup(response.text, "lxml")
            teamLogo = bs.find('div', class_='ms-entity-header_img-wrapper').find('img',
                                                                                  class_='ms-item_img ms-item_img--3_2').get(

                'src')
            imageData = requests.get(teamLogo, verify=False).content
            with open('teamPics/' + teamName + '.jpg', 'wb') as handler:
                handler.write(imageData)
        team_return = database.get_info_team(teamName)
        database.close()
        return team_return[0], team_return[1], team_return[2], team_return[3], team_return[4]


def getDriverInfo(url, urlPhoto, *toUpdate):
    database = openDB()
    response = requests.get(url)
    bs = BeautifulSoup(response.text, "lxml")
    driverName = " ".join(bs.find('h1').text.split())
    if ((not database.driver_exists(driverName)) or (toUpdate == True)):
        driverShortedInfo = bs.find('table').find('div', class_='midpart').find('table').find('table').find('tr')
        driverShortedInfo = driverShortedInfo.find_all('div', class_='news8')
        driverShortedInfo = [dataUnit.text.split() for dataUnit in driverShortedInfo][:-1]
        driverShortedInfo = ["".join(list(driverShortedInfo[1][-1])[1:-1]), ", ".join(
            driverShortedInfo[2][0].split('\''))]  # —Å—Ç—Ä–∞–Ω–∞ —Ä–æ–∂–¥–µ–Ω–∏—è, –¥–µ–±—é—Ç
        driverShortedInfo[0] = driverShortedInfo[0].split("(")[-1]
        driverShortedInfo[
            0] = f"{driverShortedInfo[0]} {flagsEmoji.get(translator.translate(driverShortedInfo[0], dest='en').text.lower())}"
        driverUnprocessedStatistics = bs.find('table').find('div', class_='midpart').find('table').find(
            'table').find_all(
            'table')
        if driverUnprocessedStatistics[0].find('div', class_='news8b', text='\n–õ—É—á—à–µ–µ –º–µ—Å—Ç–æ –≤ –≥–æ–Ω–∫–µ'):
            winOrHighestPosition = "–õ—É—á—à–µ–µ –º–µ—Å—Ç–æ –≤ –≥–æ–Ω–∫–µ"
        else:
            winOrHighestPosition = "–ü–æ–±–µ–¥—ã:"
        driverUnprocessedStatistics = [table.find_all('div', class_='news8') for table in driverUnprocessedStatistics]
        driverUnprocessedStatistics = [["".join(one_div.text.split()) for one_div in driverUnprocessedStatistics[0]],
                                       [" ".join(one_div.text.split()) for one_div in driverUnprocessedStatistics[1]]]
        driverWorldChampionshipWins = driverUnprocessedStatistics[1].count('1 –º–µ—Å—Ç–æ')
        driverStatistics = f"<b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∏–ª–æ—Ç–∞:</b>" \
                           f"\n\n<b>–ß–µ–º–ø–∏–æ–Ω—Å–∫–∏–µ —Ç–∏—Ç—É–ª—ã: </b>{driverWorldChampionshipWins} üèÜ" \
                           f"\n<b>–£—á–∞—Å—Ç–∏—è –≤ –ì—Ä–∞–Ω-–ü—Ä–∏:</b> {driverUnprocessedStatistics[0][0]}" \
                           f"\n<b>–°—Ç–∞—Ä—Ç—ã –≤ –ì—Ä–∞–Ω-–ü—Ä–∏:</b> {driverUnprocessedStatistics[0][2]}"
        if winOrHighestPosition != "–ü–æ–±–µ–¥—ã:":
            driverStatistics += f"\n<b>–õ—É—á—à–µ–µ –º–µ—Å—Ç–æ –≤ –≥–æ–Ω–∫–µ:</b> {driverUnprocessedStatistics[0][4]}"
            driverUnprocessedStatistics[0][4] = 0
        driverStatistics += f"\n<b>–ü–æ–¥–∏—É–º—ã:</b> {driverUnprocessedStatistics[0][1]}" \
                            f"\n‚Äî –ü–æ–±–µ–¥—ã: {driverUnprocessedStatistics[0][4]} ü•á" \
                            f"\n‚Äî 2 –º–µ—Å—Ç–∞: {driverUnprocessedStatistics[0][6]}  ü•à" \
                            f"\n‚Äî 3 –º–µ—Å—Ç–∞: {driverUnprocessedStatistics[0][8]}  ü•â" \
                            f"\n<b>–ü–æ—É–ª-–ø–æ–∑–∏—Ü–∏–∏:</b> {driverUnprocessedStatistics[0][3]}" \
                            f"\n<b>–ü–µ—Ä–≤—ã–µ –ª–∏–Ω–∏–∏:</b> {driverUnprocessedStatistics[0][5]}" \
                            f"\n<b>–õ—É—á—à–∏–µ –∫—Ä—É–≥–∏:</b> {driverUnprocessedStatistics[0][7]}" \
                            f"\n<b>–ó–∞—á–µ—Ç–Ω—ã–µ –æ—á–∫–∏:</b> {driverUnprocessedStatistics[0][9]}\n\n"
        detailedStatistics = []
        yearList = []
        for data in driverUnprocessedStatistics[1]:
            if data == '':
                data = '0'
            if "".join(list(data[-5:])) in ['–º–µ—Å—Ç–æ', '=']:
                if data == '=' and yearList[2] == '0':
                    yearList = []
                    continue
                else:
                    yearList.append(data)
                detailedStatistics.append(yearList)
                yearList = []
                continue
            if ("".join(list(data)[:2]) == '20' and len(list(data)) == 4) and len(yearList) == 8:
                yearList.append(detailedStatistics[-1][-1])
                detailedStatistics.append(yearList)
                yearList = []
            if yearList == [] and ("".join(list(data)[:2]) != '20' and len(list(data)) != 4):
                yearList = [detailedStatistics[-1][0]]
            yearList.append(data)
        driverStatistics += f"<b>–ì–æ–¥ –ö–æ–º–∞–Ω–¥–∞</b> ‚Äî –°—Ç–∞—Ä—Ç—ã ‚Äî –û—á–∫–∏ ‚Äî –ü–æ–¥–∏—É–º—ã ‚Äî –ü–æ–±–µ–¥—ã ‚Äî –ü–æ—É–ª-–ø–æ–∑–∏—Ü–∏–∏ ‚Äî –õ—É—á—à–∏–µ –∫—Ä—É–≥–∏ ‚Äî –ú–µ—Å—Ç–æ –≤ –ª–∏—á–Ω–æ–º –∑–∞—á–µ—Ç–µ\n\n"
        for year in detailedStatistics:
            driverStatistics += f"<b>{' '.join(year[:2])}</b> ‚Äî {' ‚Äî '.join(year[2:-1])} ‚Äî {year[-1].split()[0]}\n"
        response = requests.get(urlPhoto)
        bs = BeautifulSoup(response.text, "lxml")
        driverNationality = bs.find('img', class_='ms-entity-header_flag').get('title').lower()
        driverNationality = f"{translator.translate(driverNationality, dest='ru').text.capitalize()} {flagsEmoji.get(driverNationality)}"
        driverAgeData = bs.find('div', class_='ms-entity-header_start').find('span',
                                                                             class_='ms-entity-header_age').text.split()
        driverAgeData = [int("".join(driverAgeData[-1].split(')'))), list(map(int, driverAgeData[0].split('-')))]
        try:
            teamName = bs.find('div', class_='ms-entity-header_start').find('a',
                                                                            class_='ms-driver-header_team-title ms-link').text
            driverNumber = bs.find('div', class_='ms-driver_number ms-mr').text
        except AttributeError:
            teamName = "–ù–µ—Ç –∫–æ–º–∞–Ω–¥—ã"
            driverNumber = "(–ù–µ—Ç –Ω–æ–º–µ—Ä–∞)"

        driverInfo = (f"<b>{driverName} ‚Ññ{driverNumber}</b>\n\n"
                      f"<b>–ö–æ–º–∞–Ω–¥–∞:</b> {teamName}\n"
                      f"<b>–í–æ–∑—Ä–∞—Å—Ç:</b> {driverAgeData[0]}\n"
                      f"<b>–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è:</b> {driverAgeData[1][2]}.{driverAgeData[1][1]}.{driverAgeData[1][0]}\n"
                      f"<b>–ú–µ—Å—Ç–æ —Ä–æ–∂–¥–µ–Ω–∏—è:</b> {driverShortedInfo[0]}\n"
                      f"<b>–ì—Ä–∞–∂–¥–∞–Ω—Å—Ç–≤–æ:</b> {driverNationality}\n"
                      f"<b>–î–µ–±—é—Ç –≤ –§–æ—Ä–º—É–ª–µ-1:</b> {driverShortedInfo[1]}\n\n")
        response = requests.get(urlPhoto)
        bs = BeautifulSoup(response.text, "lxml")
        if not os.path.exists('driverPics/'):
            os.mkdir('driverPics/')
        driverPhoto = bs.find('img', class_="ms-item_img ms-item_img--3_2").get('src')
        imageData = requests.get(driverPhoto, verify=False).content
        if not os.path.exists('driverPics/' + driverName + '.jpg'):
            with open('driverPics/' + driverName + '.jpg', 'wb') as handler:
                handler.write(imageData)
        database.add_info_driver(driverStatistics, driverName, driverInfo)
    else:
        if not os.path.exists('driverPics/'):
            os.mkdir('driverPics/')
            response = requests.get(urlPhoto)
            bs = BeautifulSoup(response.text, "lxml")
            teamLogo = bs.find('div', class_='ms-entity-header_img-wrapper').find('img',
                                                                                  class_='ms-item_img ms-item_img--3_2').get(

                'src')
            imageData = requests.get(teamLogo, verify=False).content
            with open('driverPics/' + driverName + '.jpg', 'wb') as handler:
                handler.write(imageData)
        elif not os.path.exists('driverPics/' + driverName + '.jpg'):
            response = requests.get(urlPhoto)
            bs = BeautifulSoup(response.text, "lxml")
            teamLogo = bs.find('div', class_='ms-entity-header_img-wrapper').find('img',
                                                                                  class_='ms-item_img ms-item_img--3_2').get(

                'src')
            imageData = requests.get(teamLogo, verify=False).content
            with open('driverPics/' + driverName + '.jpg', 'wb') as handler:
                handler.write(imageData)
        driver_info = database.get_info_driver(driverName)
        return driver_info
    database.close()
    return driverStatistics, driverName, driverInfo

def tickets_to_BahrainGP(*toUpdate):
    database = openDB()
    GPPhotoName = "BahrainGP.jpg"
    BahrainGPTicketTypes = []
    BahrainGPTicketPrices = []
    if toUpdate:
        response = requests.get(ticketsToBahrain)
        bs = BeautifulSoup(response.text, 'lxml')
        BahrainGPTicketTypes = bs.find('div', class_='table table_grandstandtickets').find_next('div', class_='tablebody').find_all('div', class_='product cell')
        BahrainGPTicketTypes = [[" ".join(ticketType.find_next('strong').text.split()[:-1]), "".join(ticketType.find_next('strong').text.split()[-1].split(ticketType.find_next('span', class_='producttime').text)), ticketType.find_next('span', class_='producttime').text] for ticketType in BahrainGPTicketTypes]
        BahrainGPTicketPrices = bs.find('div', class_='table table_grandstandtickets').find_next('div', class_='tablebody').find_all('div', class_='price cell')
        BahrainGPTicketPrices = [" ".join(ticketPrice.text.split()) for ticketPrice in BahrainGPTicketPrices]
        database.add_ticket_info(BahrainGPTicketTypes, BahrainGPTicketPrices)
    else:
        tickets = database.get_tickets()
        for i in range(len(tickets)):
            if BahrainGPTicketTypes.count(list(tickets[i][:-1])) == 0:
                BahrainGPTicketTypes.append(list(tickets[i][:-1]))
                BahrainGPTicketPrices.append(tickets[i][-1])
    database.close()
    return BahrainGPTicketTypes, BahrainGPTicketPrices, GPPhotoName
tickets_to_BahrainGP(True)

def update_info():
    database = openDB()
    last_update = database.get_last_update_time()
    if (time.time() - last_update > 604800):
        getCalendar(current_year, True)
        for team in teamURLs.keys():
            getTeamInfo(teamURLs.get(team), teamPhotoURLs.get(team), True)
        for driver in driverURLs.keys():
            getDriverInfo(driverURLs.get(driver), driverPhotoURLs.get(driver), True)
        database.log_update_time(time.time())
    elif (time.time() - last_update > 3600):
        tickets_to_BahrainGP(True)
    database.close()

update_info()
